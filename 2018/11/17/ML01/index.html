<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="机器学习杂谈"><meta name="keywords" content="ML"><meta name="author" content="南华coder"><meta name="copyright" content="南华coder"><title>机器学习杂谈 | 南华coder的空间</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#一、开篇"><span class="toc-number">1.</span> <span class="toc-text">一、开篇</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、监督学习"><span class="toc-number">1.1.</span> <span class="toc-text">1、监督学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、决策树和集成学习"><span class="toc-number">1.2.</span> <span class="toc-text">2、决策树和集成学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3、神经网络和深度学习的渊源"><span class="toc-number">1.3.</span> <span class="toc-text">3、神经网络和深度学习的渊源</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4、特征工程"><span class="toc-number">1.4.</span> <span class="toc-text">4、特征工程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5、特征工程-amp-深度学习"><span class="toc-number">1.5.</span> <span class="toc-text">5、特征工程 &amp; 深度学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6、模型评估"><span class="toc-number">1.6.</span> <span class="toc-text">6、模型评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二、常见的监督学习算法模型"><span class="toc-number">2.</span> <span class="toc-text">二、常见的监督学习算法模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、LR（逻辑回归）"><span class="toc-number">2.1.</span> <span class="toc-text">1、LR（逻辑回归）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、SVM-支持向量机"><span class="toc-number">2.2.</span> <span class="toc-text">2、SVM(支持向量机)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3、NB-朴素贝叶斯"><span class="toc-number">2.3.</span> <span class="toc-text">3、NB(朴素贝叶斯)</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">南华coder</div><div class="author-info__description text-center">于无声处听惊雷,于无色处见繁花</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">36</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">49</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">11</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">南华coder的空间</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">机器学习杂谈</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-11-17</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/机器学习/">机器学习</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p><strong>高能预警</strong>：本人非算法开发，以下是我的一些浅见。</p>
<h3 id="一、开篇"><a href="#一、开篇" class="headerlink" title="一、开篇"></a>一、开篇</h3><p>自有机器学习以来，算法模型中就有了区分；分为监督学习，无监督学习，半监督学习和强化学习等。</p>
<h4 id="1、监督学习"><a href="#1、监督学习" class="headerlink" title="1、监督学习"></a>1、监督学习</h4><ul>
<li><p>机器学习中<strong>大部分任务</strong>都是监督学习任务；在监督学习中，分类和回归是其两大主题。分类中名声最大的是：<strong>逻辑回归</strong>(Logistic regression)、<strong>朴素贝叶斯</strong>(Naive Bayes) 和 <strong>支持向量机</strong>(Support Vector Machine，SVM) 。</p>
</li>
<li><p>在工业界曾经有<strong>一招LR打天下</strong>的”传说”，这里的LR就是逻辑回归；早些年做CTR预估时候，<strong>人工特征海洋 + LR</strong>用得非常多，很多算法工程师大部分时间埋头搞特征工程；</p>
</li>
<li><strong>朴素贝叶斯</strong>(Naive Bayes)是个开挂的存在，它将<strong>贝叶斯原理</strong>应用到机器学习中，而后机器学习中贝叶斯学派声明鹊起，与旧贵族统计学派在机器学习中鼎足而立；它强假设输入的数据的特征都是独立的，在文本分类中表现出很好的效果，可谓是入门nlp都必须了解的算法之一了。</li>
<li><strong>支持向量机</strong>(Support Vector Machine，SVM) 当之无愧是监督学习中的无冕之王，自上世纪90年代诞生之后，在机器学习界掀起“腥风血雨”，它利用核技巧，在属于两个不同类别的两组数据之间找到良好的分类边界，将线性不可分问题转为高纬空间的线性可分问题，借此达到了分类的目的。因为SVM的存在，将<strong>多层神经网络</strong>的研究打进冷宫；多层神经网络是深度学习的前身。直到2012年，因为深度学习在ImageSet竞赛中的完胜，神经网络的研究才再次复苏，直至形成今天的野火燎原之势。</li>
<li>监督学习中另一个主题是回归，最基础的的当然是<strong>线性回归</strong>(Linear regression)，模型虽然简单，但是预测个房价，股票价格这种高大上的事情也还是有着不错的表现。</li>
<li>非监督学习比较尴尬，在工业界，更多起到打辅助的左右；有聚类，降维和关联规则三大主题，聚类中用的较多反而是简单的K-means，PCA和SVD用来做数据降维，关联规则那块好像在推荐系统用的稍微多些。</li>
</ul>
<h4 id="2、决策树和集成学习"><a href="#2、决策树和集成学习" class="headerlink" title="2、决策树和集成学习"></a>2、决策树和集成学习</h4><ul>
<li>决策树是监督学习中比较特殊的模型，说他特殊，是因为它不像LR、SVM和NB直接上手，大家喜欢使用将决策树作为集成学习的基础学习器，比较著名的是<strong>随机森林</strong>(Random Forest)、<strong>梯度提升树</strong>(GBDT)，决策树的实现经历了ID3, C4.5，CART三个阶段，在随机森林、梯度提升树里面用的是CART这个分类回归树。从CART的名字也看出来，不仅仅可以做回归，也能做分类。粗暴理解就是，分类时候好多CART投票分类结果，回归时候，取CART预测值得平均数。</li>
<li>GBDT有个超级经典的实现，XgBoost。在Kaggle比赛中，XgBoost近乎霸主级别的存在；江湖有传言，图片图像等机器学习问题用Keras（深度学习库），浅层机器学习用XgBoost。</li>
</ul>
<h4 id="3、神经网络和深度学习的渊源"><a href="#3、神经网络和深度学习的渊源" class="headerlink" title="3、神经网络和深度学习的渊源"></a>3、神经网络和深度学习的渊源</h4><ul>
<li>我认为，没有神经网络，就没有深度学习；虽然业界有说法，不用神经网络就也能实现深度学习；但是神经网络真的真的很厉害，虽然很长一段时间不被看好，因为两层的神经网络连个异或都处理不了，的确有理由被看不上；但是随着反向传播算法发现，神经网络层数不断加深，在工业界发挥牛逼闪闪的光芒。</li>
<li>你可能想不到，权重，阈值，激活函数这些简简单单的东西，怎么能解决计算机视觉、语音识别这种非常难的问题，这些问题连当年风光无限的SVM都败下阵来。</li>
</ul>
<h4 id="4、特征工程"><a href="#4、特征工程" class="headerlink" title="4、特征工程"></a>4、特征工程</h4><ul>
<li><p>有句老话：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。在传统机器学习领域，做好特征工程很重要；工业界有句老话，70%多的时间在做特征工程；</p>
</li>
<li><p>比较尴尬的是，市面上多是讲解机器学习算法模型的书，讲解算法和模型的奥妙是他们的主题，提供的试验数据也都是已经处理好的，并不需要特征工程处理，但是实际工程中不是这样。特征工程的处理依赖领域知识和经验依旧是主流，但是业界很多项目处于安全、隐私等考虑，不会透露底层的特征工程的处理。</p>
</li>
</ul>
<h4 id="5、特征工程-amp-深度学习"><a href="#5、特征工程-amp-深度学习" class="headerlink" title="5、特征工程 &amp; 深度学习"></a>5、特征工程 &amp; 深度学习</h4><ul>
<li>深度学习有自动获取特征的能力，可以对输入的低阶特征进行组合、变换，得到高阶特征，但是这个能力只是对于某些领域(如图像、语音)有比较好的效果。</li>
<li>在其他领域，如自然语言处理中，输入的字或词都是离散、稀疏的值，不像图片一样是连续、稠密的。输入原始数据进行组合、变换得到的高阶特征并不是那么有效。而且有的语义并不来自数据，而来自人们的先验知识，所以利用先验知识构造的特征是很有帮助的。</li>
<li>总的来说，在深度学习中，特征工程仍然适用；神经网络能对特征自动进行排列组合，所以只要输入一阶特征就行，省去了手动构造高阶特征的工作量。</li>
</ul>
<h4 id="6、模型评估"><a href="#6、模型评估" class="headerlink" title="6、模型评估"></a>6、模型评估</h4><ul>
<li>模型评估很重要，是向别人证明你的模型怎么好的依据，我也就知道过拟合、欠拟合、交差验证、ROC、分类中查全率，查准率这些概念，没有个比较整体的认识，后面抽时间了解后再来补充。</li>
</ul>
<h3 id="二、常见的监督学习算法模型"><a href="#二、常见的监督学习算法模型" class="headerlink" title="二、常见的监督学习算法模型"></a>二、常见的监督学习算法模型</h3><p>哈哈，先留坑，后面慢慢填</p>
<h4 id="1、LR（逻辑回归）"><a href="#1、LR（逻辑回归）" class="headerlink" title="1、LR（逻辑回归）"></a>1、LR（逻辑回归）</h4><ul>
<li>线性模型的基础上增加了sigmoid函数，处理二分类问题，广义的线性模型，在CTR预估中有大作用</li>
</ul>
<h4 id="2、SVM-支持向量机"><a href="#2、SVM-支持向量机" class="headerlink" title="2、SVM(支持向量机)"></a>2、SVM(支持向量机)</h4><ul>
<li><p>可以处理非线性问题，深度学习未火之前，是学术界和工业界的热点，</p>
<p>数据规模较小时，能够构建出数据间的非线性关系，</p>
<p>1、SVM的原始公式是如何由实际问题产生，算法的灵魂</p>
<p>2、SVM原始问题到对偶问题的数学推导公式</p>
</li>
</ul>
<h4 id="3、NB-朴素贝叶斯"><a href="#3、NB-朴素贝叶斯" class="headerlink" title="3、NB(朴素贝叶斯)"></a>3、NB(朴素贝叶斯)</h4><ul>
<li>基于贝叶斯定理的一组有监督学习算法，<strong>朴素</strong>：“简单”地假设每对特征之间相互独立；</li>
<li>在很多实际情况下，朴素贝叶斯工作得很好，特别是<strong>文档分类</strong>和<strong>垃圾邮件过滤</strong>。这些工作都要求 一个小的训练集来估计必需参数。</li>
</ul>
<p><a href="http://sklearn.apachecn.org/cn/0.19.0/modules/naive_bayes.html" target="_blank" rel="noopener">http://sklearn.apachecn.org/cn/0.19.0/modules/naive_bayes.html</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">南华coder</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://buaa0300/nanhuacoder.com/2018/11/17/ML01/">http://buaa0300/nanhuacoder.com/2018/11/17/ML01/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://buaa0300/nanhuacoder.com">南华coder的空间</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ML/">ML</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/11/20/ML02-DTree/"><i class="fa fa-chevron-left">  </i><span>机器学习中的树模型</span></a></div><div class="next-post pull-right"><a href="/2018/04/15/iOS-NSURLProtocol/"><span>NSURLProtocol基础</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By 南华coder</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>