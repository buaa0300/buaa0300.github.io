<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="推荐迷雾(一):再见推荐系统"><meta name="keywords" content="推荐,冷启动,EE"><meta name="author" content="南华coder"><meta name="copyright" content="南华coder"><title>推荐迷雾(一):再见推荐系统 | 南华coder的空间</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#序言"><span class="toc-number">1.</span> <span class="toc-text">序言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一、开篇"><span class="toc-number">2.</span> <span class="toc-text">一、开篇</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二、推荐系统的评估指标和方法"><span class="toc-number">3.</span> <span class="toc-text">二、推荐系统的评估指标和方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、评估指标"><span class="toc-number">3.1.</span> <span class="toc-text">1、评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1、评分预测的评估"><span class="toc-number">3.1.1.</span> <span class="toc-text">1-1、评分预测的评估</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2、TopN推荐的评估"><span class="toc-number">3.1.2.</span> <span class="toc-text">1-2、TopN推荐的评估</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-3、覆盖率"><span class="toc-number">3.1.3.</span> <span class="toc-text">1-3、覆盖率</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-3、其他指标"><span class="toc-number">3.1.4.</span> <span class="toc-text">1-3、其他指标</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、评估方法"><span class="toc-number">3.2.</span> <span class="toc-text">2、评估方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#三、推荐系统架构"><span class="toc-number">4.</span> <span class="toc-text">三、推荐系统架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、Offline层（离线层）"><span class="toc-number">4.1.</span> <span class="toc-text">1、Offline层（离线层）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、Nearline层（近线层）"><span class="toc-number">4.2.</span> <span class="toc-text">2、Nearline层（近线层）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3、Online层（在线层）"><span class="toc-number">4.3.</span> <span class="toc-text">3、Online层（在线层）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#四、推荐系统中的冷启动和EE问题"><span class="toc-number">5.</span> <span class="toc-text">四、推荐系统中的冷启动和EE问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、朴素Bandit"><span class="toc-number">5.1.</span> <span class="toc-text">1、朴素Bandit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、汤普森采样-Thompson-sampling-算法"><span class="toc-number">5.2.</span> <span class="toc-text">2、汤普森采样(Thompson sampling)算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3、UCB算法"><span class="toc-number">5.3.</span> <span class="toc-text">3、UCB算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4、Epsilon贪婪-Epsilon-Greedy-算法"><span class="toc-number">5.4.</span> <span class="toc-text">4、Epsilon贪婪(Epsilon-Greedy)算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#五、Bandit算法的工程实现"><span class="toc-number">6.</span> <span class="toc-text">五、Bandit算法的工程实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1、LinUCB"><span class="toc-number">6.1.</span> <span class="toc-text">1、LinUCB</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2、COFIBA"><span class="toc-number">6.2.</span> <span class="toc-text">2、COFIBA</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3、其他"><span class="toc-number">6.3.</span> <span class="toc-text">3、其他</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TODO"><span class="toc-number">7.</span> <span class="toc-text">TODO</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">南华coder</div><div class="author-info__description text-center">于无声处听惊雷,于无色处见繁花</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">37</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">49</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">11</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">南华coder的空间</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">推荐迷雾(一):再见推荐系统</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-11-21</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/推荐/">推荐</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h3 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h3><p><em>花非花，雾非雾。夜半来，天明去。来如春梦不多时，去似朝云无觅处。</em></p>
<p>​    用白居易的诗作为《推荐迷雾》系列的开始，本人非推荐算法工程师，但是工作中也和算法打过些交道，也曾于13年粗读过项亮博士的《推荐系统实战》，这本12年出版的“旧”书如今再读起来，更多一番体会；虽然近些年，机器学习尤其是深度学习给传统推荐学习带来新的变化，但是这些新兴的推荐技术依旧有传统的推荐算法模型的影子。</p>
<p><img src="/nanhuacoder.com/2018/11/21/Recommend01/jianghu.jpeg" alt="江湖"></p>
<h3 id="一、开篇"><a href="#一、开篇" class="headerlink" title="一、开篇"></a>一、开篇</h3><ul>
<li>推荐产生的背景：信息过载，用户需求不确定</li>
<li>推荐三步骤：召回，预估和排序</li>
</ul>
<h3 id="二、推荐系统的评估指标和方法"><a href="#二、推荐系统的评估指标和方法" class="headerlink" title="二、推荐系统的评估指标和方法"></a>二、推荐系统的评估指标和方法</h3><h4 id="1、评估指标"><a href="#1、评估指标" class="headerlink" title="1、评估指标"></a>1、评估指标</h4><h5 id="1-1、评分预测的评估"><a href="#1-1、评分预测的评估" class="headerlink" title="1-1、评分预测的评估"></a>1-1、评分预测的评估</h5><ul>
<li><p>RMSE (均方根误差，加大预测不准物品评分的惩罚)</p>
</li>
<li><p>MAE（平均绝对误差）</p>
</li>
</ul>
<h5 id="1-2、TopN推荐的评估"><a href="#1-2、TopN推荐的评估" class="headerlink" title="1-2、TopN推荐的评估"></a>1-2、TopN推荐的评估</h5><ul>
<li>在这里用到了<strong>准确率</strong>、<strong>召回率</strong>和<strong>F-1 Score</strong>三个度量值</li>
<li><strong>召回率</strong>（Recall）：用户消费的内容，是由推荐提供的占比</li>
<li><strong>准确率</strong>（Precision）：推荐的内容中，用户消费的占比</li>
<li><strong>F-1 Score</strong> </li>
</ul>
<p>$$<br>F_1 Score = \frac{2 x recall * precision}{recall + precision}<br>$$</p>
<p><strong>召回率</strong>表示在原始样本的正样本中，最后被正确预测为正样本的概率；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算召回率和准确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PrecisionRecall</span><span class="params">(test,N)</span>:</span></span><br><span class="line">	hit = <span class="number">0</span></span><br><span class="line">	n_recall = <span class="number">0</span></span><br><span class="line">	n_precision = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> user,item <span class="keyword">in</span> test.items():</span><br><span class="line">		rank = Recommend(user,N)</span><br><span class="line">		hit += len(rank &amp; items)</span><br><span class="line">		n_recall += len(items)</span><br><span class="line">		n_precision += N</span><br><span class="line">	<span class="keyword">return</span> [hit/(<span class="number">1.0</span> * n_recall),hit/(<span class="number">1.0</span>*n_precision)]</span><br></pre></td></tr></table></figure>
<ul>
<li>为了全面评估TopN推荐的准确率和召回率，一般选取不同推荐列表长度N，计算一组准确率/召回率，然后画出准确率/召回率曲线。</li>
<li>在工程实践中，TopN推荐更合适，因为对于推荐的内容来说，预测用户会不会看，比预测用户看了内容后给多少分更重要。</li>
</ul>
<h5 id="1-3、覆盖率"><a href="#1-3、覆盖率" class="headerlink" title="1-3、覆盖率"></a>1-3、覆盖率</h5><p>推荐系统对物品长尾的发掘能力，简单的定义是推荐物品占总物品集合的比例。当然还有更好的指标来定义覆盖率。</p>
<ul>
<li>信息熵：</li>
<li>基尼系数：</li>
</ul>
<h5 id="1-3、其他指标"><a href="#1-3、其他指标" class="headerlink" title="1-3、其他指标"></a>1-3、其他指标</h5><ul>
<li>多样性、新颖性、惊喜度、信任度、实时性、健壮性，商业目标等等，具体参考《推荐系统实战》中的内容</li>
</ul>
<h4 id="2、评估方法"><a href="#2、评估方法" class="headerlink" title="2、评估方法"></a>2、评估方法</h4><ul>
<li><p>离线评估：速度快，不需要用户参与；在用户的历史数据上做评估，和线上真实效果有偏差；只能评估少数指标。</p>
</li>
<li><p>用户调查：主要的形式是问卷调查，成本高</p>
</li>
<li><p>在线实验：目前最普遍的做法是ABtest，目前主采用多层重叠实验设计，这些在后面的文章重点介绍</p>
</li>
</ul>
<h3 id="三、推荐系统架构"><a href="#三、推荐系统架构" class="headerlink" title="三、推荐系统架构"></a>三、推荐系统架构</h3><ul>
<li>推荐系统是产品的核心，而推荐算法仅仅是推荐系统中的一部分；以NetFlix的推荐系统架构为例，介绍经典的推荐系统架构。</li>
<li>在NetFlix推荐系统架构中，分为三层：Offline层（离线层）、Nearline层（近线层）和  Online层（在线层）</li>
</ul>
<h4 id="1、Offline层（离线层）"><a href="#1、Offline层（离线层）" class="headerlink" title="1、Offline层（离线层）"></a>1、Offline层（离线层）</h4><ul>
<li>这一层批量、周期性地<strong>抽取数据</strong>，<strong>训练模型</strong>；训练得到的模型可以用于为用户计算推荐结果。协同过滤、矩阵分解一般在这层做，Hadoop、Spark分布式计算也在这一层。</li>
<li>Offline阶段的推荐结果或模型在Nearline层被更新，产生最终的推荐结果，呈现给用户。</li>
</ul>
<h4 id="2、Nearline层（近线层）"><a href="#2、Nearline层（近线层）" class="headerlink" title="2、Nearline层（近线层）"></a>2、Nearline层（近线层）</h4><ul>
<li>Nearline要处理处理实时数据流(流计算），执行计算任务：从事件队列中获取最新的一个或少许几个用户反馈行为，将这些用户已经反馈过的物品从离线推荐结果中剔除，然后用这几个反馈行为作为样本，以小批量梯度下降的优化方法去更新融合模型的参数。</li>
</ul>
<h4 id="3、Online层（在线层）"><a href="#3、Online层（在线层）" class="headerlink" title="3、Online层（在线层）"></a>3、Online层（在线层）</h4><ul>
<li>用户使用App/浏览Web，消费展示内容，产生行为事件数据，如页面曝光，按钮点击等，实时被收集走，一边进入分布式文件系统中做存储，给Offline使用，一边流向Nearline的<strong>消息队列</strong>，供Nearline的<strong>流计算</strong>使用。</li>
<li>用户发出请求，等待推荐结果；Online层必须实施响应用户请求，要快，要有兜底，Online层处理的一般是已经预处理后的推荐结果。</li>
</ul>
<h3 id="四、推荐系统中的冷启动和EE问题"><a href="#四、推荐系统中的冷启动和EE问题" class="headerlink" title="四、推荐系统中的冷启动和EE问题"></a>四、推荐系统中的冷启动和EE问题</h3><ul>
<li>在推荐系统中有两个经典问题：<strong>冷启动</strong>和<strong>EE</strong>(探索和利用问题)。</li>
<li>Bandit算法提供了一种有效的解决办法；其中<strong>冷启动</strong>的本质是：推荐系统没有历史数据，无法预测用户偏好；可分为用户冷启动，物品冷启动和系统冷启动。<strong>EE问题</strong>是指，是选择现在不确定的一些方案，但未来可能会有高收益的方案；还是选择现在可能最佳的方案；本质是一个选择的问题。</li>
<li>Bandit 算法来源于历史悠久的赌博学，它要解决这样的问题：一个赌徒去摇老虎机，赌场中有的老虎机一模一样，但是每个老虎机吐钱的概率不一样，他不知道每个老虎机吐钱的概率分布是什么，那么每次该选择哪个老虎机可以做到最大化收益呢？这就是<strong>多臂赌博机问题</strong>（Multi-armed bandit problem, K-armed bandit problem, MAB）</li>
</ul>
<p><img src="/nanhuacoder.com/2018/11/21/Recommend01/mab.png" alt="MAB问题"></p>
<ul>
<li><p>假设我们已经经过一些试验，得到了当前每个老虎机的吐钱的概率，如果想要获得最大的收益，我们会一直摇哪个吐钱概率最高的老虎机，这就是Exploitation。但是，当前获得的信息并不是老虎机吐钱的真实概率，可能还有更好的老虎机吐钱概率更高，因此还需要进一步探索，这就是Exploration问题。</p>
</li>
<li><p>Bandit解决MAB或者EE问题的策略是：有策略地走一步看一步，这些策略就是Bandit算法，经典的Bandit算法分别是：<strong>朴素Bandit、汤普森采样、UCB和Epsilon贪婪算法</strong>。</p>
</li>
</ul>
<h4 id="1、朴素Bandit"><a href="#1、朴素Bandit" class="headerlink" title="1、朴素Bandit"></a>1、朴素Bandit</h4><p><strong>原理</strong>：先随机试若干次，计算每个臂的平均收益，一直选均值最大那个臂。</p>
<h4 id="2、汤普森采样-Thompson-sampling-算法"><a href="#2、汤普森采样-Thompson-sampling-算法" class="headerlink" title="2、汤普森采样(Thompson sampling)算法"></a>2、汤普森采样(Thompson sampling)算法</h4><p><strong>原理</strong>：</p>
<ul>
<li>每个臂维护一个beta(a，b)分布，每次用现有的beta分布产生一个随机数，输出随机数最大的臂（较快，随机性高）</li>
</ul>
<p><strong>beta(a，b)分布特点</strong>：</p>
<ul>
<li>a+b值越大，分布曲线就越窄，分布就越集中；</li>
<li>a/(a+b)值越大，分布中心越靠近1，反之越靠近0；</li>
</ul>
<p><strong>采样过程</strong>：</p>
<ul>
<li><p>假设a是用户的点击次数，b是没有得到用户的点击次数</p>
</li>
<li><p>每次取出所有候选的参数a和b，用贝塔分布产生一个随机数</p>
</li>
<li><p>随机数排序，输出最大值对应的候选</p>
</li>
<li><p>如果用户点击，对应的候选a加1，反之b加1</p>
</li>
</ul>
<p><strong>分析</strong>：</p>
<ul>
<li>如果一个候选被选中的次数很多（a+b很大），分布变窄，对应的分布产生的随机数基本在中心位置，接近平均收益。</li>
<li>如果a+b很大，a/(a+b)也很大，那么分布产生的随机数越接近1，平均收益很好，进入利用阶段；</li>
<li>如果a+b很小，说明候选的好坏不能确定，分布很宽，可能得到一个较大的随机数，排序时候可能被优先输出，起到了探索的目的。</li>
</ul>
<h4 id="3、UCB算法"><a href="#3、UCB算法" class="headerlink" title="3、UCB算法"></a>3、UCB算法</h4><p><strong>原理</strong>：</p>
<ul>
<li>以每个候选的平均收益作为基准线进行选择</li>
<li>对于每次被选择不足的给与照顾</li>
<li>选择倾向于那些确定收益较好的候选</li>
</ul>
<p><strong>简言之</strong>，均值越大，标准差越小，被选中的概率会越来越大 (相对慢一点，确定性高)</p>
<h4 id="4、Epsilon贪婪-Epsilon-Greedy-算法"><a href="#4、Epsilon贪婪-Epsilon-Greedy-算法" class="headerlink" title="4、Epsilon贪婪(Epsilon-Greedy)算法"></a>4、Epsilon贪婪(Epsilon-Greedy)算法</h4><p><strong>原理：</strong></p>
<ul>
<li>先选一个(0,1)之间较小的值，作为Epsilon，然后每次以1-epsilon的概率选取当前收益最大的臂，以epsilon的随机概率选取一个臂。（后期不需要较大探索，epsilon需要衰减）</li>
<li>Epsilon可以控制探索和利用的程度，Epsilon越接近0，在探索上就越保守；Epsilon越接近1，在探索上就越激进。</li>
</ul>
<p><img src="/nanhuacoder.com/2018/11/21/Recommend01/bandit-performance.png" alt="Bandit算法算法模拟试验效果"></p>
<p><strong>总结</strong>：UCB算法和汤普森采样算法效果更好些。</p>
<h3 id="五、Bandit算法的工程实现"><a href="#五、Bandit算法的工程实现" class="headerlink" title="五、Bandit算法的工程实现"></a>五、Bandit算法的工程实现</h3><p>​    上面介绍的<strong>朴素Bandit、汤普森采样、UCB和Epsilon贪婪算法</strong>都是经典的Bandit算法，在工程中很少使用；实际中，我们采用的是上下文Bandit算法，比较常见的是LinUCB算法和COFIBA算法</p>
<h4 id="1、LinUCB"><a href="#1、LinUCB" class="headerlink" title="1、LinUCB"></a>1、LinUCB</h4><p><strong>概述</strong>：</p>
<ul>
<li><p>传统的 Bandit 算法并没有考虑臂的特征信息，也就是说并没有考虑上下文信息，而yahoo在2010年提出的，一种结合上下文的 Bandit算法——LinUCB (linear UCB)算法。</p>
</li>
<li><p>LinUCB 算法可以将当前用户的特征、物品特征构成所有的相关特征，然后根据每个臂维护的特征系数,计算出预估收益。由于加入了特征，所以收敛速度比 UCB 更快。</p>
</li>
<li>LinUCB的不足：同时处理的候选臂数量不能太多，不超过几百个最佳。因为每一次要计算每一个候选臂的期望收益和置信区间，一旦候选太多，计算代价将不可接受。其实这也是所有的 Bandit 算法的缺点。</li>
</ul>
<p><strong>原理：</strong></p>
<ul>
<li><p>LinUCB 假设一个物品推送给用户之后，获得的收益与相关特征呈<strong>线性关系</strong>，这里的相关特征就是指上下文信息。LinUCB 有两个版本：<strong>Disjoint</strong> 和 <strong>Hybrid</strong>，Disjoint 表示不同臂之间的不相关，也就是说参数不共享，Hybrid 表示臂之间共享一些参数。</p>
</li>
<li><p>Disjoint 模型：假设每个臂包含一个物品，我们在每一次选择时，用户与物品的的特征构成了上下文信息，表示为 x，维度为 d，每个臂维护了一个 d 维的表示特征系数的向量 θ，使用 c 表示本次选择的收益，如果用户点击了就为 1，否则为 0。我们假定：</p>
</li>
</ul>
<p>  根据p’ + ∆来选择合适的臂。p’的计算基于有监督的学习方法。我们为每个老虎机维护一个特征向量D，同时上下文特征我们写作θ，然后通过收集的反馈进行有监督学习：</p>
<ul>
<li><p>加入特征信息，用User和Item的特征预估回报及其置信区间，选择置信区间上界最大的Item推荐，观察回报后更新线性关系的参数，以此达到试验学习的目的。</p>
</li>
<li><p>岭回归的求解，岭回归适合样本数少于特征的数据集。</p>
</li>
<li><p>参考：<a href="http://www.naodongopen.com/908.html" target="_blank" rel="noopener">结合上下文信息的Bandit算法—LinUCB算法</a></p>
</li>
</ul>
<h4 id="2、COFIBA"><a href="#2、COFIBA" class="headerlink" title="2、COFIBA"></a>2、COFIBA</h4><ul>
<li>2016年提出，COFIBA算法的不同有两个：<ol>
<li>基于用户聚类挑选最佳的Item（相似用户集体决策的Bandit）。</li>
<li>基于用户的反馈情况调整User和Item的聚类（协同过滤部分）。</li>
</ol>
</li>
<li>在时刻t，用户来访问推荐系统，推荐系统需要从已有的候选池子中挑一个最佳的物品推荐给他，然后观察他的反馈，用观察到的反馈来更新挑选策略。 这里的每个物品都有一个特征向量，所以这里的Bandit算法是context相关的。 这里依然是用岭回归去拟合用户的权重向量，用于预测用户对每个物品的可能反馈（payoff），这一点和linUCB算法是一样的</li>
</ul>
<ul>
<li><p>bandit结合协同过滤。</p>
<p><a href="https://blog.csdn.net/heyc861221/article/details/80129310" target="_blank" rel="noopener">https://blog.csdn.net/heyc861221/article/details/80129310</a></p>
</li>
</ul>
<h4 id="3、其他"><a href="#3、其他" class="headerlink" title="3、其他"></a>3、其他</h4><ul>
<li>Exploit-Explore这一对矛盾一直客观存在，Bandit算法是公认的一种比较好的解决EE问题的方案。但解决Explore，势必就是要冒险，势必要走向未知，而这显然就是会伤害用户体验的：明知道用户肯定喜欢A，你还偏偏以某个小概率给推荐非A。</li>
<li>实际上，很少有公司会采用这些理性的办法做Explore，反而更愿意用一些盲目主观的方式。究其原因，可能是因为：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、互联网产品生命周期短，而Explore又是为了提升长期利益的，所以没有动力做；</span><br><span class="line">2、用户使用互联网产品时间越来越碎片化，Explore的时间长，难以体现出Explore 的价值；</span><br><span class="line">3、同质化互联网产品多，用户选择多，稍有不慎，用户用脚投票，分分钟弃你于不顾；</span><br><span class="line">4、已经成规模的平台，红利杠杠的，其实是没有动力做Explore的。</span><br></pre></td></tr></table></figure>
<ul>
<li>所以做Explore要精心设计，必须保证质量。</li>
</ul>
<h3 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h3><ul>
<li><p>bandit添加对应的源码实现</p>
</li>
<li><p>ABTest的分层实验设计</p>
</li>
<li>召回中的协同过滤和隐语义模型, 矩阵分解</li>
<li>CTR预估的进化，特征工程 + LR -&gt; GBDT + LR -&gt; FM -&gt;FFM -&gt; DeepFM/Wide&amp;Deep/…</li>
<li>排序怎么做</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">南华coder</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://buaa0300/nanhuacoder.com/2018/11/21/Recommend01/">http://buaa0300/nanhuacoder.com/2018/11/21/Recommend01/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://buaa0300/nanhuacoder.com">南华coder的空间</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/推荐/">推荐</a><a class="post-meta__tags" href="/tags/冷启动/">冷启动</a><a class="post-meta__tags" href="/tags/EE/">EE</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/11/30/Recommend02/"><i class="fa fa-chevron-left">  </i><span>推荐迷雾(一):话说ABTest实验</span></a></div><div class="next-post pull-right"><a href="/2018/11/20/ML02-DTree/"><span>机器学习中的树模型</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By 南华coder</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>